# Configuration file for network training
#
# These options define the various properties of a model. They are extracted by the function
#   read_out_config_file in
# the file
#   utilities/input_utilities.py.
#
#
#
#def execute_nn(list_filename, folder_name, loss_opt, class_type, nn_arch, 
#                swap_4d_channels=None, batchsize=64, epoch=[-1,-1], epochs_to_train=-1, n_gpu=(1, 'avolkov'), use_scratch_    ssd=False,
#                zero_center=False, shuffle=(False,None), str_ident='', train_logger_display=100, train_logger_flush=-1,
#                train_verbose=2, n_events=None):
#
#    """
#     Core code that trains a neural network.
# 
#     Parameters
#     ----------

#     list_filename : str
#         Path to a list file which contains pathes to all the h5 files that should be used for training and evaluation.


#    folder_name : str
#             Name of the folder of this model in which everything will be saved. E.g., the summary.txt log file is located in     here.



#    loss_opt : tuple(dict, dict/str/None,)
#            Tuple that contains 1) the loss_functions and loss_weights as dicts (this is the losses table from the toml file)
#            and 2) the metrics.
# The loss(es) of the model are listed here. Every loss has an identifier as a keyword,
# and a loss function that it will use. Can also give a weight to each loss.

[losses]
dx = {function="mse", weight=10}
dy = {function="mse", weight=10}
dz = {function='mean_absolute_error', weight=15}
vx = {function='mean_absolute_error', weight=1}
vy = {function='mean_absolute_error', weight=1}
vz = {function='mean_absolute_error', weight=1}
vt = {function='mean_absolute_error', weight=1e-10}
e  = {function='mean_absolute_error'}
by = {function='mean_absolute_error', weight=10}
dx_err = {function='loss_uncertainty_mse'}
dy_err = {function='loss_uncertainty_mse'}
dz_err = {function='loss_uncertainty_mse', weight=1.25}
vx_err = {function='loss_uncertainty_mse'}
vy_err = {function='loss_uncertainty_mse'}
vz_err = {function='loss_uncertainty_mse'}
vt_err = {function='loss_uncertainty_mse', weight=1e-10}
e_err  = {function='loss_uncertainty_mse', weight=1e-2}
by_err = {function='loss_uncertainty_mse'}

[keyword_arguments]
# Positional arguments of the execute_nn function in run_nn.py

#     class_type : tuple(int, str)
#         Declares the number of output classes / regression variables and a string identifier to specify the exact output     classes.
#         I.e. (2, 'track-shower')
#	 int = 'None' for regression (?) 

class_type = [2, 'charged-neutral']

#class_type = ['None', 'energy_dir_bjorken-y_vtx_errors']

#     nn_arch : str
#         Architecture of the neural network. Currently, only 'VGG' or 'WRN' are available.

nn_arch = 'WRN'
#nn_arch = 'VGG'

#     batchsize : int
#        Batchsize that should be used for the training / inferencing of the cnn.


#     epoch : List[int, int]
#        Declares if a previously trained model or a new model (=0) should be loaded.
#        The first argument specifies the last epoch, and the second argument is the last train file number if the train
#        dataset is split over multiple files. Can also give [-1,-1] to automatically load the most recent epoch.


#    epochs_to_train : int
#        How many new epochs should be trained by running this function. -1 for infinite.


#    swap_4d_channels : None/str
#        For 4D data input (3.5D models). Specifies, if the channels of the 3.5D net should be swapped.
#        Currently available: None -> XYZ-T ; 'yzt-x' -> YZT-X, TODO add multi input options

# Additional options
#swap_4d_channels = 'xyz-t_and_xyz-c_single_input'

#For 3D nothing for now.
#swap_4d_channels = 'None'

#    n_gpu : tuple(int, str)
#        Number of gpu's that the model should be parallelized to [0] and the multi-gpu mode (e.g. 'avolkov') [1].


#    use_scratch_ssd : bool
#        Declares if the input files should be copied to the node-local SSD scratch space (only working at Erlangen CC).


#    zero_center : bool
#        Declares if the input images ('xs') should be zero-centered before training.

zero_center = true

#    shuffle : tuple(bool, None/int)
#        Declares if the training data should be shuffled before the next training epoch [0].
#        If the train dataset is too large to be shuffled in place, one can preshuffle them n times before running
#        OrcaNet, the number n should then be put into [1].


#    str_ident : str
#        Optional string identifier that gets appended to the modelname. Useful when training models which would have
#        the same modelname. Also used for defining models and projections!

str_ident = 'test_2'

#    train_logger_display : int
#        How many batches should be averaged for one line in the training log files.


train_logger_display=250

#    train_logger_flush : int
#       After how many lines the training log file should be flushed. -1 for flush at the end of the epoch only.

train_logger_flush=-1

#    train_verbose : int
#       verbose option of keras.model.fit_generator.

train_verbose = 1

#    n_events : None/int
#       For testing purposes. If not the whole .h5 file should be used for training, define the number of events.
# 

#n_events = 32000

